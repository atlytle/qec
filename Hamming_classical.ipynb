{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot2(A, B):\n",
    "    \"Matrix multiplication mod 2.\"\n",
    "    return np.mod(np.dot(A,B), 2)\n",
    "\n",
    "def basis_vec(size, index):\n",
    "    \"Basis vector in R^size, in the index direction.\"\n",
    "    _v = np.zeros(size)\n",
    "    _v[index] = 1.0\n",
    "    return _v\n",
    "\n",
    "def to_base10(binary_vec):\n",
    "    \"Convert binary vector to corresponding base 10 integer.\"\n",
    "    res = 0\n",
    "    for i, x in enumerate(binary_vec):\n",
    "        res += x*(2**i)\n",
    "    return int(res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical Hamming codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Andrew Lytle\n",
    "Reference: https://en.wikipedia.org/wiki/Hamming(7,4)  \n",
    "The [7, 4] code encodes 4 logical bits into 7 encoded bits, using the additional bits as parity checks to detect all single-bit and two-bit errors, and can correct single-bit errors. (The minimal Hamming distance between any two codewords is 3). There is a very nice image that encapsulates how this works:  \n",
    "<img src=\"./Hamming7_4.svg\" alt=\"Graphical depiction of Hamming [7,4,3]\" />  \n",
    "Here the 'd' entries are the encoded logical bits (data), the 'p' entries give the parity checks on the data.\n",
    "\n",
    "Let us think for a moment about how the encoding will work.The parity bits should identify which bit has been corrupted---we will take bits 1, 2, and 4 as parity bits, and reading the value of these will indicate which of the 7 bits has been corrupted, with 000 indicating no error! In general, if we have $m$ parity bits, we can encode $2^m-m-1$ logical bits with the parity bits giving the syndrome measurement. This structure gives a class of [$2^m-1$, $2^m-m-1$, 3] codes.\n",
    "\n",
    "To generate the code words, we need a $7 \\times 4$ matrix. Reading off the image,\n",
    "we encode the parity entries according to coverage of the data entries.\n",
    "For example, p1 covers d1, d2, and d4, so it corresponds to the row [1, 1, 0, 1].\n",
    "The data simply \"passes through\" i.e. the 'd' entries form a $4 \\times 4$ identity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = np.array([\n",
    "              [1, 1, 0, 1],  # p1     \n",
    "              [1, 0, 1, 1],  # p2\n",
    "              [1, 0, 0, 0],  # d1\n",
    "              [0, 1, 1, 1],  # p4\n",
    "              [0, 1, 0, 0],  # d2\n",
    "              [0, 0, 1, 0],  # d3\n",
    "              [0, 0, 0, 1]   # d4\n",
    "              ]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The related matrix $H$ is the parity check matrix, used to compute the error syndrome on a code word. By construction, we want $Hx=0$, $\\forall x \\in C$. $H$ encodes the parity check equations, and so is $3 \\times 7$ (in general $(n-k) \\times n$). Again referring to the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = np.array([\n",
    "            [1, 0, 1, 0, 1, 0, 1],  # p1 = d1 + d2 + d4 \n",
    "            [0, 1, 1, 0, 0, 1, 1],  # p2 = d1 + d3 + d4\n",
    "            [0, 0, 0, 1, 1, 1, 1]  # p3 = d2 + d3 + d4 \n",
    "            ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By construction, $G$ will take us from a 4-bit vector to a 7-bit encoded vector, which will have a parity check of 0, since it is a valid codeword. In other words, $H G = 0$. If there is a single bit-flip error, $H$ will tell us where it occurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot2(H, G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see below how $H$ can be used to detect, and correct an error.\n",
    "We also introduce a decoding matrix $R$ that simply pulls out the data bits.\n",
    "Note that an error on a parity bit, while detected, doesn't need to be corrected\n",
    "in order for the word to be correctly transmitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_l = array([1, 1, 0, 0])\n",
      "x_p = array([0, 1, 1, 1, 1, 0, 0])\n",
      "dot2(H,x_p) = array([0, 0, 0])\n",
      "6\n",
      "[0. 0. 0.]\n",
      "x_l_t = array([1., 1., 0., 0.])\n",
      "Word transmitted succesfully: True\n"
     ]
    }
   ],
   "source": [
    "x_l = np.array([1,1, 0, 0])  # Logical word.\n",
    "print(f\"{x_l = }\")\n",
    "x_p = dot2(G, x)  # Physical codeword.\n",
    "print(f\"{x_p = }\")\n",
    "print(f\"{dot2(H,x_p) = }\")\n",
    "x_p_e = x_p + basis_vec(7, 2)  # Introduce an error on bit 3.\n",
    "syndrome = dot2(H, x_p_e)\n",
    "print(to_base10(syndrome))  # Error occurred on this bit.\n",
    "x_p_c = x_p_e + basis_vec(7, to_base10(syndrome)-1)\n",
    "print(dot2(H, x_p_c))\n",
    "R = np.array([\n",
    "            [0, 0, 1, 0, 0, 0, 0],\n",
    "            [0, 0, 0, 0, 1, 0, 0],\n",
    "            [0, 0, 0, 0, 0, 1, 0],\n",
    "            [0, 0, 0, 0, 0, 0, 1],\n",
    "])\n",
    "x_l_t = dot2(R, x_p_c)  # Transmitted logical word.\n",
    "print(f\"{x_l_t = }\")\n",
    "print(f\"Word transmitted succesfully: {(x_l_t == x_l).all()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_single_bitflip():\n",
    "    rng = np.random.default_rng()\n",
    "    def random_word():"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dual codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For any linear code $C$ (recall that a linear code is defined by the property that x+y is a codeword if x and y are codewords), we may define a dual code $C^\\perp$ as the set of all vectors $x$ with $<x, c>=0$, $\\forall c \\in C$. This inner product is mod 2, and so a given vector $x$ can be in both $C$ and $C^\\perp$ (i.e. our \"usual\" intuition about orthogonality for vector spaces in $R^n$ doesn't hold here).\n",
    "\n",
    "The generator matrix of the $C$ is the parity check matrix of $C^\\perp$, and vice versa.\n",
    "Let's consider a concrete example of this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSS codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
